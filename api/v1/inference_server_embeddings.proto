syntax = "proto3";

package llmoperator.embeddings.server.v1;

import "google/api/annotations.proto";

option go_package = "github.com/llm-operator/inference-manager/api/v1";

message CreateEmbeddingRequest {
   // This can be a string or an array of strings, but we use string assuming that it is more common.
  string input = 1;
  string model = 2;

  string encoding_format = 3;
  int32 dimensions = 4;

  string user = 5;
}

message Embedding {
  int32 index = 1;
  repeated double embedding = 2;
  string object = 3;
}
