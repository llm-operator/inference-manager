syntax = "proto3";

package llmoperator.inference_engine.v1;

import "google/api/annotations.proto";
import "google/protobuf/empty.proto";

option go_package = "github.com/llm-operator/inference-manager/api/v1";

message PullModelRequest {
    // id is the model id.
    string id = 1;
}

message DeleteModelRequest {
    // id is the model id.
    string id = 1;
}

message Model {
    // id is the model id.
    string id = 1;
}

message ListModelsRequest {}

message ListModelsResponse {
    repeated Model models = 1;
}

service InferenceEngineInternalService {
    rpc PullModel(PullModelRequest) returns (google.protobuf.Empty);
    rpc DeleteModel(DeleteModelRequest) returns (google.protobuf.Empty);
    rpc ListModels(ListModelsRequest) returns (ListModelsResponse);
}
