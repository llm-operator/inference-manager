global:
  objectStore:
    s3:
      endpointUrl:
      region:
      bucket:

  awsSecret:
    name:
    accessKeyIdKey:
    secretAccessKeyKey:

  ingress:
    ingressClassName:

  worker:
    registrationKeySecret:
      name:
      key:
    tls:
      enable: false

ollamaPort: 8080

# The following default values work if model-manager-server runs in the same namespace.
inferenceManagerServerWorkerServiceAddr: inference-manager-server-worker-service-grpc:8082
modelManagerServerWorkerServiceAddr: model-manager-server-worker-service-grpc:8082

replicaCount: 1
image:
  repository: public.ecr.aws/cloudnatix/llm-operator/inference-manager-engine
  pullPolicy: IfNotPresent

serviceAccount:
  create: false
  name: ""

podAnnotations:
nodeSelector:
affinity:
tolerations:

version:

resources:
  gpu: 1

autoscaling:
  # TODO(kenji): Enable once Keda installation is supported in the Terraform provisioning.
  enableKeda: false
  scaledobject:
    minReplicaCount: 1
    maxReplicaCount: 2
    prometheusServerAddr:
